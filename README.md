# Taski

Приложение для планирования своих задач.

# Локальная разработка

Локальную разработку можно вести как и по отдельности: фронтенд и бекенд, так и
вместе.

Ниже инструкция для всех трех режимов разработки

## Фронтенд

Инструкция по локальной разработке доступна в соответствующем [README](https://github.com/AnnSokolovaa/virtualization-final-project/blob/main/frontend/README.md).

Для сбоорки образа достаточно выполнить `docker build ./frontend -t frontend`.

Данная команда соберет образ, который используется для развертки. В образ был
добавлен nginx для облегчения итогового образа с помшощью `multi-stage build`:
в конечном образе используются только статические html и alpine образ nginx.

Ради столь легкого образа пришлось потратить некоторое время для того чтобы
подружить nginx и django, перенаправляя запросы по роуту `/api` на бекенд.
Конфигурация описана в [nginx.conf](https://github.com/AnnSokolovaa/virtualization-final-project/blob/main/frontend/nginx.conf).

Более того, реализован докер образ для тестрования приложения. Он использует
тот же базовый образ, что и продакшн, так что гарантировано одинаковое
окружение. Для тестирования достаточно выпнолить `docker build -f
Dockerfile.test ./frontend -t frontend-test && docker run frontend-test`.

Эти же тесты выполняются при пуше на main благодаря github actions, о них
ниже.

## Бекенд

Для локальной разработки достаточно выполнить последовательно следующие команды

```bash
python -m venv /opt/venv
source venv/bin/activate
pip install --no-cache-dir -r requirements.txt
python manage.py migrate
python manage.py runserver 0.0.0.0:8000
```

Как видно, процесс достаточно трудоемкий, так что вместо него можно выполнять
одну команду `docker build ./backend -t backend && docker run backend`.

## Все вместе

Если же хочется самому развернуть обе части так, чтобы они друг с другом
успешно общались, то можно воспользоваться `сompose.yml` в корне директории.
Достаточно выполнить `docker compose up -d`. Данная команда соберет оба
образа и развернет соответствующие им контейнеры и подключит их к одной сети.
Данные бекенда будут персистентны между развертываниями.

Так как я пошла по пути nginx для облегчения образа фронтенда, в сети
соединяющих оба сервиса по умолчанию не работали localhost у обоих сервисов.
Вместо них пришлось использовать host backend в настройках nginx, который dns
общей сети из сompose корректно переведет в ip бекенда, и разрешить хост
backend в [настройках бека](https://github.com/AnnSokolovaa/virtualization-final-project/blob/main/backend/backend/settings.py#L12).

Так же из сompose файла можно запускать тестирование командой
`docker compose build frontend-tests && docker compose run frontend-tests`.

Эта сборка в точности собирает образ тестирования из секции про фронтенд.

К сожалению, я не успела углубиться в устройство обоих состовляющих для
реализации hot reloading обоих компонент, так что возможно придется
пересобирать образы при каждом изменении.

# k8s

Так же в проекте приложен файл декларации деплоя проекта на k8s кластер.

Деплой разворачивает три реплики фронтенда с load balancer'ом для распределения
нагрузкии и три реплики бекенда.

При наличии кластера, достаточно выполнить `kubectl apply -f deployment.yaml`

У меня нет своего удаленного кластера, так что разработка велась с
использованием `minikube`. Для тестирования работостосопности декларации
(помимо вывода команды `kubecl get all`) использовалась команда `minikube
service frontend`, которая создает временный туннель между фронтендом и
компьютером, что позволяет зайти на сайт и убедиться, что он работает.

В частности, из за отсутствия удаленного кластера, развертка на удаленный
кластер не была реализована.

# Github actions

При любом пуше и пулл реквесте на ветку main запускаются автоматизированные github actions: [пример запуска](https://github.com/AnnSokolovaa/virtualization-final-project/actions/runs/13620776427/job/38069902197). Этапы:

- После чекаута кода и логина в dockerhub запускаются фронтенд тесты
- После них собираются и пушатся образы используя docker compose
  - Реализация устроена таким образом, что пушиться они будут с тегом продакшн
  - При этом выполнив команду `docker compose push`, образы запушатся с тегом
    `latest`

После пуша не репозиторий можно было бы сделать деплой с использованием `docker
сompose` на удаленный сервер, но у меня его тоже нет, так что данный шаг
пропускается.
